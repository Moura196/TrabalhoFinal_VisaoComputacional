# TrabalhoFinal_VisaoComputacional

Projeto final de VisÃ£o Computacional com ambiente completo de preparaÃ§Ã£o tÃ©cnica usando PyTorch.

## ğŸ“‹ DescriÃ§Ã£o

Este repositÃ³rio contÃ©m a infraestrutura completa para desenvolvimento de projetos de visÃ£o computacional, incluindo:

- âœ… Ambiente configurado com PyTorch e dependÃªncias essenciais
- âœ… Pipeline de prÃ©-processamento padronizado (224x224, normalizaÃ§Ã£o)
- âœ… Data loaders com shuffle para treinamento
- âœ… Scripts de verificaÃ§Ã£o de GPU/CPU
- âœ… Exemplos de uso e testes

## ğŸš€ InÃ­cio RÃ¡pido

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/Moura196/TrabalhoFinal_VisaoComputacional.git
cd TrabalhoFinal_VisaoComputacional
```

2. Execute o script de configuraÃ§Ã£o interativa:
```bash
python setup_environment.py
```

Ou instale manualmente as dependÃªncias:
```bash
pip install -r requirements.txt
```

### VerificaÃ§Ã£o do Ambiente

Execute o script de verificaÃ§Ã£o para testar as importaÃ§Ãµes e disponibilidade de GPU/CPU:

```bash
python verify_environment.py
```

Este script irÃ¡:
- âœ“ Verificar todas as importaÃ§Ãµes de pacotes
- âœ“ Detectar se GPU estÃ¡ disponÃ­vel
- âœ“ Testar operaÃ§Ãµes bÃ¡sicas de tensores
- âœ“ Executar um treinamento "hello world"

## ğŸ“¦ DependÃªncias

### Deep Learning
- **PyTorch** (>=2.0.0) - Framework principal de deep learning
- **Torchvision** (>=0.15.0) - UtilitÃ¡rios e datasets para visÃ£o computacional

### Processamento de Dados
- **NumPy** (>=1.24.0) - ComputaÃ§Ã£o numÃ©rica
- **Pandas** (>=2.0.0) - ManipulaÃ§Ã£o de dados
- **Pillow** (>=10.0.0) - Processamento de imagens

### Machine Learning
- **Scikit-learn** (>=1.3.0) - Algoritmos de machine learning

### VisualizaÃ§Ã£o
- **Matplotlib** (>=3.7.0) - CriaÃ§Ã£o de grÃ¡ficos
- **Seaborn** (>=0.12.0) - VisualizaÃ§Ã£o estatÃ­stica

### Utilidades
- **tqdm** (>=4.65.0) - Barras de progresso

## ğŸ”§ Pipeline de PrÃ©-processamento

O mÃ³dulo `data_preprocessing.py` fornece um pipeline padronizado para preparaÃ§Ã£o de imagens:

### CaracterÃ­sticas Principais

- **Resize automÃ¡tico**: Todas as imagens sÃ£o redimensionadas para 224x224 pixels
- **NormalizaÃ§Ã£o por canal**: Utiliza estatÃ­sticas do ImageNet (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
- **Data augmentation**: Opcional para treinamento (flip horizontal, rotaÃ§Ã£o, color jitter)
- **Data loaders**: Com shuffle automÃ¡tico para conjunto de treino

### Uso BÃ¡sico

```python
from data_preprocessing import get_preprocessing_pipeline, create_data_loaders
from PIL import Image

# Criar preprocessador para treino (com augmentation)
train_preprocessor = get_preprocessing_pipeline(mode='train')

# Criar preprocessador para avaliaÃ§Ã£o (sem augmentation)
eval_preprocessor = get_preprocessing_pipeline(mode='eval')

# Processar uma imagem
image = Image.open('caminho/para/imagem.jpg')
tensor = train_preprocessor(image)  # Shape: (3, 224, 224)

# Criar dataset customizado
from data_preprocessing import CustomImageDataset

dataset = CustomImageDataset(
    images=lista_de_imagens,
    labels=lista_de_labels,
    transform=train_preprocessor
)

# Criar data loaders
loaders = create_data_loaders(
    train_dataset=train_dataset,
    val_dataset=val_dataset,
    batch_size=32,
    shuffle_train=True  # Shuffle ativo para treino
)

# Iterar sobre batches
for images, labels in loaders['train']:
    # images: (batch_size, 3, 224, 224)
    # labels: (batch_size,)
    pass
```

### Exemplo Completo

```python
import torch
from torch.utils.data import Dataset
from data_preprocessing import (
    get_preprocessing_pipeline,
    CustomImageDataset,
    create_data_loaders
)

# 1. Preparar preprocessamento
train_transform = get_preprocessing_pipeline(mode='train')
val_transform = get_preprocessing_pipeline(mode='eval')

# 2. Criar datasets
train_dataset = CustomImageDataset(
    images=train_images,
    labels=train_labels,
    transform=train_transform
)

val_dataset = CustomImageDataset(
    images=val_images,
    labels=val_labels,
    transform=val_transform
)

# 3. Criar data loaders
loaders = create_data_loaders(
    train_dataset=train_dataset,
    val_dataset=val_dataset,
    batch_size=32,
    num_workers=4,
    shuffle_train=True  # Shuffle habilitado para treino
)

# 4. Treinar modelo
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

for epoch in range(num_epochs):
    for images, labels in loaders['train']:
        images = images.to(device)
        labels = labels.to(device)
        
        # Seu cÃ³digo de treinamento aqui
        outputs = model(images)
        loss = criterion(outputs, labels)
        # ...
```

## ğŸ“Š Estrutura do Projeto

```
TrabalhoFinal_VisaoComputacional/
â”œâ”€â”€ README.md                    # Este arquivo
â”œâ”€â”€ requirements.txt             # DependÃªncias do projeto
â”œâ”€â”€ setup_environment.py         # Script de configuraÃ§Ã£o interativa
â”œâ”€â”€ verify_environment.py        # Script de verificaÃ§Ã£o do ambiente
â”œâ”€â”€ data_preprocessing.py        # Pipeline de prÃ©-processamento
â””â”€â”€ .gitignore                   # Arquivos ignorados pelo git
```

## ğŸ§ª Testes

### Testar ImportaÃ§Ãµes e GPU/CPU

```bash
python verify_environment.py
```

### Testar Pipeline de PrÃ©-processamento

```bash
python data_preprocessing.py
```

## ğŸ’¡ CaracterÃ­sticas do Pipeline

### 1. PadronizaÃ§Ã£o de Entrada

- **DimensÃµes fixas**: 224x224 pixels (padrÃ£o para transfer learning)
- **Formato**: Tensor PyTorch (C, H, W) = (3, 224, 224)
- **Tipo de dados**: Float32
- **Intervalo de valores**: Normalizado usando estatÃ­sticas ImageNet

### 2. NormalizaÃ§Ã£o por Canal

```python
# EstatÃ­sticas do ImageNet
mean = [0.485, 0.456, 0.406]  # RGB
std = [0.229, 0.224, 0.225]   # RGB
```

### 3. Data Augmentation (Treino)

- Flip horizontal aleatÃ³rio (p=0.5)
- RotaÃ§Ã£o aleatÃ³ria (Â±15 graus)
- Color jitter (brightness, contrast, saturation, hue)

### 4. Data Loaders

- **Shuffle**: Habilitado automaticamente para treino
- **Pin memory**: Habilitado quando GPU disponÃ­vel
- **Drop last**: True para treino, False para validaÃ§Ã£o
- **Num workers**: ConfigurÃ¡vel (padrÃ£o: 4)

## ğŸ¯ PrÃ³ximos Passos

ApÃ³s configurar o ambiente, vocÃª pode:

1. **Preparar seus dados**: Organize suas imagens e labels
2. **Criar dataset customizado**: Use `CustomImageDataset` como template
3. **Definir modelo**: Crie ou carregue um modelo de rede neural
4. **Treinar**: Use os data loaders para treinar seu modelo
5. **Avaliar**: Use o data loader de validaÃ§Ã£o para avaliar o modelo

## ğŸ“ Notas

- O pipeline Ã© otimizado para transfer learning com modelos prÃ©-treinados no ImageNet
- Para outros casos de uso, vocÃª pode customizar os parÃ¢metros de normalizaÃ§Ã£o
- GPU Ã© opcional mas recomendado para treinamento mais rÃ¡pido
- Os data loaders usam `pin_memory=True` automaticamente quando GPU estÃ¡ disponÃ­vel

## ğŸ¤ Contribuindo

Para contribuir com este projeto:

1. FaÃ§a um fork do repositÃ³rio
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto Ã© parte do trabalho final de VisÃ£o Computacional.

## ğŸ‘¥ Autores

- Moura196

## ğŸ™ Agradecimentos

- PyTorch team pelo excelente framework
- ImageNet dataset pelos dados de treinamento e estatÃ­sticas de normalizaÃ§Ã£o